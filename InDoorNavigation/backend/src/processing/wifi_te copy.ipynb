{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import tslearn\n",
    "import math\n",
    "import random\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_points_data_filename =  \"_points.json\"\n",
    "\n",
    "with open(raw_points_data_filename, 'r') as f:\n",
    "    json_data = json.load(f) \n",
    "\n",
    "p_data = json_data \n",
    "points = []\n",
    "for d in p_data:\n",
    "    points.extend(d['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_wifi_points(points):\n",
    "    wpoints = []\n",
    "    for p in points:\n",
    "        wp = {\n",
    "            \"x\":p['x'],\n",
    "            \"y\":p['y'],\n",
    "            \"floor\":p['floor'],\n",
    "            \"wifiData\": p['wifiData'],\n",
    "            \"gpsData\": p['gpsData'],\n",
    "            \"timestamp\":p['timestamp']\n",
    "        }\n",
    "        wpoints.append(wp)\n",
    "        \n",
    "\n",
    "    # print(len([w for w in wpoints if w['wifiData']]),len(wpoints))\n",
    "    wifi_points = [w for w in wpoints if w['wifiData']]    \n",
    "    return wifi_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.utils import to_time_series\n",
    "from tslearn.metrics import dtw_path,dtw_path_from_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0), (1, 0)], 6.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_path_from_metric(\n",
    "    s1=[[1,2,1],[1,1,2]], \n",
    "    s2=[[1,2,3]],\n",
    "    global_constraint=None, # sakoe_chiba ,itakura\n",
    "    sakoe_chiba_radius=None, # int\n",
    "    itakura_max_slope=None, # float\n",
    "    be=None, # pytorch, numpy\n",
    "    metric=lambda x, y: np.sum((x-y)**2),\n",
    ")\n",
    "\n",
    "# list , similary score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rss_by_threshold(rss_array, threshold):\n",
    "    return [rss for rss in rss_array if rss >= threshold]\n",
    "\n",
    "def linear_interpolation(rss1, rss2, n, i):\n",
    "    return ((n - i) / n) * rss1 + (i / n) * rss2\n",
    "\n",
    "def adaptive_interpolation(rss_array, f1, f2):\n",
    "    n = math.floor(f1 / f2)\n",
    "    interpolated_rss = []\n",
    "    for i in range(len(rss_array) - 1):\n",
    "        for j in range(n):\n",
    "            interpolated_rss.append(linear_interpolation(rss_array[i], rss_array[i + 1], n, j))\n",
    "    interpolated_rss.append(rss_array[-1])  # Include the last original RSS\n",
    "    return interpolated_rss\n",
    "\n",
    "def normalize(array):\n",
    "    mean = np.mean(array)\n",
    "    std_dev = np.std(array)\n",
    "    return [(val - mean) / std_dev for val in array]\n",
    "\n",
    "def calculate_weights(rss_array):\n",
    "    max_rss = max(rss_array)\n",
    "    return [math.exp(rss / max_rss) for rss in rss_array]\n",
    "\n",
    "def compute_weighted_distance(rss, rssdb, weights):\n",
    "    p = len(rss)\n",
    "    distance = 0\n",
    "    for k in range(p):\n",
    "        distance += weights[k] * (rss[k] - rssdb[k]) ** 2\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Generate random database fingerprints\n",
    "def generate_random_fingerprints(num_fingerprints, num_rss_values):\n",
    "    fingerprints = []\n",
    "    for _ in range(num_fingerprints):\n",
    "        ssid = f\"network{_ + 1}\"\n",
    "        rss = [random.randint(-90, -30) for _ in range(num_rss_values)]\n",
    "        x = random.uniform(0, 50)\n",
    "        y = random.uniform(0, 50)\n",
    "        fingerprints.append({'ssid': ssid, 'rss': rss, 'x': x, 'y': y})\n",
    "    return fingerprints\n",
    "\n",
    "# Generate user inputs by slightly varying the RSS values from the database\n",
    "def generate_user_inputs(database_fingerprints, num_inputs, variation):\n",
    "    user_inputs = []\n",
    "    for _ in range(num_inputs):\n",
    "        input_entry = []\n",
    "        for db_entry in random.sample(database_fingerprints, len(database_fingerprints)):\n",
    "            ssid = db_entry['ssid']\n",
    "            rss = [rss_val + random.randint(-variation, variation) for rss_val in db_entry['rss']]\n",
    "            input_entry.append({'ssid': ssid, 'rss': rss})\n",
    "        user_inputs.append(input_entry)\n",
    "    return user_inputs\n",
    "\n",
    "# Calculate accuracy based on estimated vs actual positions\n",
    "def calculate_accuracy(estimated_positions, actual_positions):\n",
    "    total_error = 0\n",
    "    errors = []\n",
    "    for est_pos, act_pos in zip(estimated_positions, actual_positions):\n",
    "        error = math.sqrt((est_pos['x'] - act_pos['x']) ** 2 + (est_pos['y'] - act_pos['y']) ** 2)\n",
    "        errors.append(error)\n",
    "        total_error += error\n",
    "    avg_error = total_error / len(estimated_positions)\n",
    "    return errors, avg_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Generate the data\n",
    "# num_fingerprints = 50\n",
    "# num_rss_values = 5\n",
    "# num_inputs = 10\n",
    "# variation = 5\n",
    "\n",
    "# database_fingerprints = generate_random_fingerprints(num_fingerprints, num_rss_values)\n",
    "# user_inputs = generate_user_inputs(database_fingerprints, num_inputs, variation)\n",
    "\n",
    "# # Estimate positions for user inputs\n",
    "# estimated_positions = []\n",
    "# actual_positions = [{'x': entry['x'], 'y': entry['y']} for entry in random.sample(database_fingerprints, num_inputs)]\n",
    "\n",
    "# threshold = -70\n",
    "# f1 = 0.5\n",
    "# f2 = 0.125\n",
    "# sigma = 1\n",
    "# r = 5\n",
    "\n",
    "# for user_input in user_inputs:\n",
    "#     estimated_position = estimate_position(user_input, database_fingerprints, threshold, f1, f2, sigma, r)\n",
    "#     estimated_positions.append(estimated_position)\n",
    "\n",
    "# # Calculate and print accuracy\n",
    "# errors, avg_error = calculate_accuracy(estimated_positions, actual_positions)\n",
    "\n",
    "# print(\"Individual Errors:\", errors)\n",
    "# print(\"Average Error:\", avg_error)\n",
    "\n",
    "# # Example database fingerprints with positions (for reproducibility)\n",
    "# print(\"Database Fingerprints:\", database_fingerprints[:5])  # Print first 5 for brevity\n",
    "\n",
    "# # Example user inputs (for reproducibility)\n",
    "# print(\"User Inputs:\", user_inputs[:3])  # Print first 3 for brevity\n",
    "\n",
    "# # Estimated positions\n",
    "# print(\"Estimated Positions:\", estimated_positions)\n",
    "# def mdtw_with_wls(rss, rssdb, weights):\n",
    "#     n = len(rss)\n",
    "#     m = len(rssdb)\n",
    "#     d = np.zeros((n, m))\n",
    "\n",
    "#     for i in range(n):\n",
    "#         for j in range(m):\n",
    "#             d[i][j] = compute_weighted_distance(rss[i], rssdb[j], weights)\n",
    "\n",
    "#     D = np.zeros((n, m))\n",
    "#     D[0][0] = d[0][0]\n",
    "\n",
    "#     for i in range(1, n):\n",
    "#         D[i][0] = d[i][0] + D[i - 1][0]\n",
    "\n",
    "#     for j in range(1, m):\n",
    "#         D[0][j] = d[0][j] + D[0][j - 1]\n",
    "\n",
    "#     for i in range(1, n):\n",
    "#         for j in range(1, m):\n",
    "#             D[i][j] = d[i][j] + min(D[i - 1][j], D[i][j - 1], D[i - 1][j - 1])\n",
    "\n",
    "#     return D[n - 1][m - 1]\n",
    "\n",
    "# def weighted_least_squares(positions, distances, sigma):\n",
    "#     weights = [1 / math.exp(di ** 2 / (2 * sigma ** 2)) for di in distances]\n",
    "#     total_weight = sum(weights)\n",
    "\n",
    "#     normalized_weights = [w / total_weight for w in weights]\n",
    "\n",
    "#     estimated_x = sum(normalized_weights[i] * positions[i][0] for i in range(len(positions)))\n",
    "#     estimated_y = sum(normalized_weights[i] * positions[i][1] for i in range(len(positions)))\n",
    "\n",
    "#     return {'x': estimated_x, 'y': estimated_y}\n",
    "\n",
    "# def match_fingerprints(user_input, database_fingerprints):\n",
    "#     matched_rss = []\n",
    "#     matched_dbrss = []\n",
    "\n",
    "#     for user_network in user_input:\n",
    "#         db_network = next((db_network for db_network in database_fingerprints if db_network['ssid'] == user_network['ssid']), None)\n",
    "#         if db_network:\n",
    "#             matched_rss.append(user_network['rss'])\n",
    "#             matched_dbrss.append(db_network['rss'])\n",
    "\n",
    "#     return {'matched_rss': matched_rss, 'matched_dbrss': matched_dbrss}\n",
    "\n",
    "# def estimate_position(user_input, database_fingerprints, threshold, f1, f2, sigma, r):\n",
    "#     matched = match_fingerprints(user_input, database_fingerprints)\n",
    "\n",
    "#     filtered_rss = [filter_rss_by_threshold(rss_array, threshold) for rss_array in matched['matched_rss']]\n",
    "\n",
    "#     interpolated_rss = [adaptive_interpolation(rss_array, f1, f2) for rss_array in filtered_rss]\n",
    "\n",
    "#     normalized_rss = [normalize(rss) for rss in interpolated_rss]\n",
    "#     normalized_dbrss = [normalize(rss) for rss in matched['matched_dbrss']]\n",
    "\n",
    "#     weights = calculate_weights([val for sublist in interpolated_rss for val in sublist])\n",
    "\n",
    "#     distances = [mdtw_with_wls(rss, normalized_dbrss[i], weights) for i, rss in enumerate(normalized_rss)]\n",
    "\n",
    "#     sorted_distances = sorted(\n",
    "#         [{'distance': d, 'position': (database_fingerprints[i]['x'], database_fingerprints[i]['y'])} for i, d in enumerate(distances)],\n",
    "#         key=lambda x: x['distance']\n",
    "#     )\n",
    "\n",
    "#     top_r = sorted_distances[:r]\n",
    "\n",
    "#     positions = [item['position'] for item in top_r]\n",
    "#     distance_values = [item['distance'] for item in top_r]\n",
    "\n",
    "#     estimated_position = weighted_least_squares(positions, distance_values, sigma)\n",
    "\n",
    "#     return estimated_position\n",
    "\n",
    "# # Example database fingerprints with positions\n",
    "# database_fingerprints = [\n",
    "#     {\n",
    "#         'ssid': 'network1',\n",
    "#         'rss': [-78, -82, -85, -88, -74],\n",
    "#         'x': 5,\n",
    "#         'y': 10\n",
    "#     },\n",
    "#     {\n",
    "#         'ssid': 'network2',\n",
    "#         'rss': [-61, -63, -60, -55, -52],\n",
    "#         'x': 15,\n",
    "#         'y': 20\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # Example user input\n",
    "# user_input = [\n",
    "#     {\n",
    "#         'ssid': 'network1',\n",
    "#         'rss': [-80, -75, -90, -60, -50]\n",
    "#     },\n",
    "#     {\n",
    "#         'ssid': 'network2',\n",
    "#         'rss': [-62, -65, -67, -70, -69]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # Parameters for position estimation\n",
    "# threshold = -70\n",
    "# f1 = 0.5  # Target sampling frequency\n",
    "# f2 = 0.125  # Original sampling frequency\n",
    "# sigma = 1  # Configuration parameter for exponential function\n",
    "# r = 2  # Number of top positions to consider\n",
    "\n",
    "# estimated_position = estimate_position(user_input, database_fingerprints, threshold, f1, f2, sigma, r)\n",
    "\n",
    "# print(\"Estimated Position:\", estimated_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json(data):\n",
    "    print(json.dumps(data,indent=2))\n",
    "\n",
    "def get_num_interpolation(f1,f2):\n",
    "    n = math.floor(f1 / f2)\n",
    "    return n\n",
    "\n",
    "def pad_vector(vector, length):\n",
    "    \"\"\"Pad or truncate vector to a specified length.\"\"\"\n",
    "    if len(vector) >= length:\n",
    "        return vector[:length]  # Truncate if longer than desired length\n",
    "    else:\n",
    "        return vector + [0] * (length - len(vector))  # Pad with zeros if shorter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ap_occurances(points):\n",
    "    ap_occurances = {}\n",
    "    for p in points:\n",
    "        for w in p['wifiData']:\n",
    "            if not w['BSSID'] in ap_occurances:\n",
    "                ap_occurances[w['BSSID']] = 0\n",
    "            ap_occurances[w['BSSID']] += 1\n",
    "    return ap_occurances\n",
    "    \n",
    "def filter_by_networks(point,nets):\n",
    "    point['wifiData'] = [p for p in point['wifiData'] if p['SSID'] in nets]\n",
    "\n",
    "def filter_by_rss_threshold(point,signal_strength_threshold):\n",
    "    point['wifiData'] = [p for p in point['wifiData'] if p['level'] >= signal_strength_threshold]\n",
    "\n",
    "def filter_by_ap_num_occurances(point,ap_occurances,ap_occurance_threshold):\n",
    "    point['wifiData'] = [p for p in point['wifiData'] if ap_occurances[p['BSSID']] >= ap_occurance_threshold]\n",
    "    \n",
    "def get_rss(point):\n",
    "    return [p['level'] for p in point['wifiData']]\n",
    "\n",
    "def filter_dataset_by_bssids(dataset, target_point, at_least_threshold):\n",
    "    # Extract BSSIDs from the target_point's WiFi data\n",
    "    target_bssids = {p['BSSID'] for p in target_point['wifiData']}\n",
    "\n",
    "    filtered_dataset = []\n",
    "    \n",
    "    for point, vector in dataset:\n",
    "        # Extract BSSIDs from the current point's vector\n",
    "        point_bssids = {p['BSSID'] for p in vector}\n",
    "\n",
    "        # Count how many BSSIDs of the target point are present in the current point\n",
    "        common_bssids = target_bssids.intersection(point_bssids)\n",
    "        \n",
    "        # Check if the number of common BSSIDs meets the threshold\n",
    "        if len(common_bssids) >= at_least_threshold:\n",
    "            filtered_dataset.append((point, vector))\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "def filter_by_vector_length(dataset, length_threshold):\n",
    "    filtered_dataset = []\n",
    "    \n",
    "    for point, vector in dataset:\n",
    "        # Check if the length of the vector meets the threshold\n",
    "        if len(vector) >= length_threshold:\n",
    "            filtered_dataset.append((point, vector))\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "    \n",
    "def get_same_aps(point1,point2):\n",
    "    np1 = point1.copy()\n",
    "    np2 = point2.copy()\n",
    "    np1['wifiData'] = []\n",
    "    np2['wifiData'] = []\n",
    "    for p1 in point1['wifiData']:\n",
    "        for p2 in point2['wifiData']:\n",
    "            if p1['SSID'] == p2['SSID'] and p1['BSSID'] == p2['BSSID']:\n",
    "                np1['wifiData'].append(p1)\n",
    "                np2['wifiData'].append(p2)\n",
    "    return np1,np2\n",
    "\n",
    "\n",
    "\n",
    "def linear_interpolation(rss1, rss2, n, i):\n",
    "    return ((n - i) / n) * rss1 + (i / n) * rss2\n",
    "\n",
    "\n",
    "def wifi_linear_interpolation(point1, point2,num_interpolation):\n",
    "    rsses = []\n",
    "    for p1 in point1['wifiData']:\n",
    "        found = False\n",
    "        for p2 in point2['wifiData']:\n",
    "            if p1['SSID'] == p2['SSID'] and p1['BSSID'] == p2['BSSID']:\n",
    "                rss = {\n",
    "                    \"RSS\": linear_interpolation(p1['level'],p2['level'], num_interpolation,len(rsses)),\n",
    "                    \"SSID\":p1['SSID'],\n",
    "                    \"BSSID\":p1['BSSID'],\n",
    "                }\n",
    "                rsses.append(rss)\n",
    "            found = True\n",
    "        if not found:\n",
    "            raise ValueError(\"invalid points\")\n",
    "    return rsses\n",
    "\n",
    "def remove_empty_reference_points(points):\n",
    "    return [\n",
    "        p for p in points \n",
    "        if 'wifiData' in p and isinstance(p['wifiData'], list) and len(p['wifiData']) > 0\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(points):\n",
    "    network_values = {}\n",
    "    bssid_values = {}\n",
    "    network_int = 0\n",
    "    bssid_int = 0\n",
    "    for p in points:\n",
    "        wifi = p['wifiData']\n",
    "        for w in wifi: \n",
    "            ssid = w['SSID']\n",
    "            bssid = w['BSSID']\n",
    "            if ssid not in network_values:\n",
    "                network_values[ssid] = network_int\n",
    "            if bssid not in network_values:\n",
    "                bssid_values[bssid] = bssid_int\n",
    "\n",
    "    return network_values,bssid_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(vector1, vector2):\n",
    "    dot_product = sum(v1 * v2 for v1, v2 in zip(vector1, vector2))\n",
    "    norm1 = math.sqrt(sum(v1 ** 2 for v1 in vector1))\n",
    "    norm2 = math.sqrt(sum(v2 ** 2 for v2 in vector2))\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 1  # Handle zero vector case\n",
    "    return 1 - dot_product / (norm1 * norm2)\n",
    "\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    return math.sqrt(sum((v1 - v2) ** 2 for v1, v2 in zip(vector1, vector2)))\n",
    "\n",
    "def manhattan_distance(vector1, vector2):\n",
    "    return sum(abs(v1 - v2) for v1, v2 in zip(vector1, vector2))\n",
    "\n",
    "def dynamic_time_warping_similarity(vector1, vector2):\n",
    "    n, m = len(vector1), len(vector2)\n",
    "    dtw_matrix = [[float('inf')] * (m + 1) for _ in range(n + 1)]\n",
    "    dtw_matrix[0][0] = 0\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = abs(vector1[i - 1] - vector2[j - 1])\n",
    "            dtw_matrix[i][j] = cost + min(dtw_matrix[i - 1][j], dtw_matrix[i][j - 1], dtw_matrix[i - 1][j - 1])\n",
    "\n",
    "    return 1 / (1 + dtw_matrix[n][m])  # Similarity, so invert the distance\n",
    "\n",
    "def calculate_distance(v1: typing.List[typing.Union[int, float]], v2: typing.List[typing.Union[int, float]], func: typing.Callable[[typing.List[float], typing.List[float]], float]) -> float:\n",
    "    if len(v1) != len(v2):\n",
    "        raise ValueError(\"Vectors must be of the same length\")\n",
    "\n",
    "    # Ensure elements are float for numeric calculations\n",
    "    vector1 = list(map(float, v1))\n",
    "    vector2 = list(map(float, v2))\n",
    "\n",
    "    # Calculate distance using the specified function\n",
    "    return func(vector1, vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fingerprint_dataset(points):\n",
    "    extra = {}\n",
    "    dataset = []\n",
    "    min_length = 999\n",
    "    max_length = -1\n",
    "    for point in points:\n",
    "        min_length = min(min_length,len(point['wifiData']))\n",
    "        max_length = max(max_length,len(point['wifiData']))\n",
    "\n",
    "    extra['max'] = max_length\n",
    "    extra['min'] = min_length\n",
    "\n",
    "    for point in points:\n",
    "        vector = create_fingerprint_vector(point,extra)\n",
    "        p = point['x'],point['y'],point['floor']\n",
    "        dataset.append((p,vector))\n",
    "    return dataset,extra\n",
    "\n",
    "def filter_dataset(dataset,point):\n",
    "    num_rsses = len(point['wifiData'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_fingerprint_vector(point,extra):\n",
    "    \n",
    "    max_rss_length = extra['max']\n",
    "    rsses = get_rss(point)\n",
    "    normal_vector = pad_vector(rsses,max_rss_length)\n",
    "    p = (point['x'],point['y'],point['floor'])\n",
    "    print(p,\"rsses:\",rsses,\"vec:\",normal_vector)\n",
    "    return normal_vector\n",
    "\n",
    "def get_wifi_result(point,points,k=1):\n",
    "    dataset, extra = create_fingerprint_dataset(points)\n",
    "    dataset = filter_dataset(dataset,point)\n",
    "    target_vector = create_fingerprint_vector(point,extra)\n",
    "    distance_func = lambda v1,v2: calculate_distance(v1,v2,euclidean_distance)\n",
    "    result = knn(dataset,target_vector,distance_func,k)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(dataset, target_vector, distance_func:typing.Callable,k=1):\n",
    "    distances = []\n",
    "    \n",
    "    for point,vector in dataset:\n",
    "        distance = distance_func(vector, target_vector)\n",
    "        distances.append((point, distance))\n",
    "\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    nearest_neighbors = distances[0:k]\n",
    "    return nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_position(knn_results):\n",
    "    x_coords = [point[0] for point, _ in knn_results]\n",
    "    y_coords = [point[1] for point, _ in knn_results]\n",
    "    floors = [point[2] for point, _ in knn_results]\n",
    "    return (sum(x_coords) / len(x_coords), sum(y_coords) / len(y_coords), round(sum(floors) / len(floors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = 0.0333\n",
    "f1 = 0.0333\n",
    "num_interpolation = get_num_interpolation(f1,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_strength_threshold = -70\n",
    "ap_occurance_threshold = 5\n",
    "nets = ['Afeka-Staff',\n",
    "'Afeka-Wifi-Open',\n",
    "'Afeka-Students']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scan(point):\n",
    "    filter_by_networks(point,nets)\n",
    "    filter_by_rss_threshold(point,signal_strength_threshold)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with wifi after rss threshold and network filtering, and num ap occurances: 158\n",
      "testing on points (with the current point): 0 - 30\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def wifi_workflow(points):\n",
    "   \n",
    "    wifi_points = normalize_wifi_points(points)\n",
    "    ap_occurances = get_ap_occurances(wifi_points)\n",
    "    for p in wifi_points:\n",
    "        filter_by_ap_num_occurances(p,ap_occurances,ap_occurance_threshold)\n",
    "    wifi_points = remove_empty_reference_points(wifi_points)\n",
    "    dataset_points = copy.deepcopy(wifi_points)\n",
    "\n",
    "    for p in wifi_points:\n",
    "        normalize_scan(p)\n",
    "\n",
    "    wifi_points = remove_empty_reference_points(wifi_points)\n",
    "\n",
    "    print(\"with wifi after rss threshold and network filtering, and num ap occurances:\",len(wifi_points))  \n",
    "\n",
    "\n",
    "    \n",
    "    # bssids = {}\n",
    "    # for p in wifi_points:\n",
    "    #     for w in p['wifiData']:\n",
    "    #         if not w['BSSID'] in bssids:\n",
    "    #             bssids[w['BSSID']] = [0,[],[]]\n",
    "    #         bssids[w['BSSID']][0] += 1\n",
    "    #         if w['SSID'] not in bssids[w['BSSID']][1]:\n",
    "    #             bssids[w['BSSID']][1].append(w['SSID'])            \n",
    "    #         bssids[w['BSSID']][2].append((p['x'],p['y'],p['floor']))\n",
    "            \n",
    "    # values_count = {}\n",
    "    # as_array = []\n",
    "    # values_count_array = []\n",
    "    # for key,value in bssids.items():\n",
    "    #     as_array.append((key,value))\n",
    "    #     if value[0] not in values_count:\n",
    "    #         values_count[value[0]] = 0\n",
    "    #     values_count[value[0]] += 1\n",
    "    \n",
    "    # for key,value in values_count.items():\n",
    "    #     values_count_array.append((key,value))\n",
    "    \n",
    "    # as_array = sorted(as_array,key=lambda x: x[1][0])\n",
    "    # values_count_array = sorted(values_count_array,key=lambda x: x[0])\n",
    "    # print(\"num unique bssids\", len(bssids.keys()), \"val:\",as_array)\n",
    "\n",
    "    \n",
    "\n",
    "    p_start = 0\n",
    "    p_end = 30\n",
    "\n",
    "    print(\"testing on points (with the current point):\",p_start,\"-\",p_end)\n",
    "\n",
    "    # print(dataset_points[0])\n",
    "    for i,scan_point in enumerate(dataset_points[p_start:p_end]):\n",
    "        \n",
    "        x = scan_point['x']\n",
    "        y = scan_point['y']\n",
    "        \n",
    "        floor = scan_point['floor']\n",
    "        normalize_point = normalize_scan(scan_point)\n",
    "        # print(normalize_point)\n",
    "        if not ((1000 > normalize_point['x'] > 300) and ( 800 > normalize_point['y'] > 250 ) and (normalize_point['floor'] == 0)):\n",
    "            continue\n",
    "\n",
    "        if len(normalize_point['wifiData']) == 0:\n",
    "            print(f\"skipping... no wifi data {i}\")\n",
    "            continue\n",
    "        wifi_result = get_wifi_result(normalize_point,wifi_points,k=4)\n",
    "        position = estimate_position(wifi_result[1:])\n",
    "        print(f\"| expected:{(x,y,floor)} | estimated: {position} | | result {wifi_result} |\")\n",
    "        # print(f\"| expected:{(x,y,floor)} | | result {wifi_result} |\")\n",
    "        \n",
    "\n",
    "\n",
    "wifi_workflow(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 622 383 0 (56, 36, 9)\n",
      "w2: 682 333 0 (83, 51, 15)\n",
      "w3: 627 333 0 (57, 35, 9)\n",
      "w4: 557 338 0 (82, 51, 18)\n",
      "nw11: ('net:', 'Afeka-Staff', 'num_rss', 2, 'num_aps', 2)\n",
      "('net:', 'Afeka-Students', 'num_rss', 2, 'num_aps', 2)\n",
      "('net:', 'Afeka-Wifi-Open', 'num_rss', 2, 'num_aps', 2)\n",
      "nw12: ('net:', 'Afeka-Staff', 'num_rss', 2, 'num_aps', 2)\n",
      "('net:', 'Afeka-Students', 'num_rss', 2, 'num_aps', 2)\n",
      "('net:', 'Afeka-Wifi-Open', 'num_rss', 2, 'num_aps', 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'RSS': -36.0, 'SSID': 'Afeka-Staff', 'BSSID': '94:b3:4f:a3:a7:54'},\n",
       " {'RSS': -44.0, 'SSID': 'Afeka-Students', 'BSSID': '94:b3:4f:a3:a7:55'},\n",
       " {'RSS': -51.0, 'SSID': 'Afeka-Wifi-Open', 'BSSID': '94:b3:4f:a3:a7:50'},\n",
       " {'RSS': -58.0, 'SSID': 'Afeka-Students', 'BSSID': '94:b3:4f:a3:25:e5'},\n",
       " {'RSS': -53.0, 'SSID': 'Afeka-Staff', 'BSSID': '94:b3:4f:a3:25:e4'},\n",
       " {'RSS': -49.0, 'SSID': 'Afeka-Wifi-Open', 'BSSID': '94:b3:4f:a3:25:e0'}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = wpoints[48].copy()\n",
    "w2 = wpoints[49].copy()\n",
    "w3 = wpoints[50].copy()\n",
    "w4 = wpoints[51].copy()\n",
    "\n",
    "\n",
    "def filter_ap(point):\n",
    "    a = len(point['wifiData'])\n",
    "    filter_by_networks(point)\n",
    "    b = len(point['wifiData'])\n",
    "    filter_by_rss_threshold(point,threshold)\n",
    "    c = len(point['wifiData'])\n",
    "    return (a,b,c)\n",
    "\n",
    "def info_wifi(point):\n",
    "    info = {}\n",
    "    for f in point['wifiData']:\n",
    "\n",
    "        if f['SSID'] not in info:\n",
    "            info[f['SSID']] = {\n",
    "                'num_rss':0,\n",
    "                'num_aps':0,\n",
    "                'BSSIDs': {}\n",
    "            }\n",
    "        \n",
    "        if f[\"BSSID\"] not in info[f['SSID']]['BSSIDs']:\n",
    "            info[f['SSID']]['BSSIDs'][f[\"BSSID\"]] = []\n",
    "            info[f['SSID']]['num_aps'] += 1\n",
    "\n",
    "\n",
    "        info[f['SSID']]['BSSIDs'][f[\"BSSID\"]].append(f['level'])\n",
    "        info[f['SSID']]['num_rss'] += 1  \n",
    "\n",
    "    \n",
    "    strings = []\n",
    "    for key,value, in info.items():\n",
    "        strings.append(str((\"net:\",key, \"num_rss\",value['num_rss'], \"num_aps\", value['num_aps'])))\n",
    "    return info,\"\\n\".join(strings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"w1:\",w1['x'],w1['y'],w1['floor'], filter_ap(w1))\n",
    "print(\"w2:\",w2['x'],w2['y'],w2['floor'], filter_ap(w2))\n",
    "print(\"w3:\",w3['x'],w3['y'],w3['floor'], filter_ap(w3))\n",
    "print(\"w4:\",w4['x'],w4['y'],w4['floor'], filter_ap(w4))\n",
    "\n",
    "# print(\"w1:\",info_wifi(w1)[1])\n",
    "# print(\"w2:\",info_wifi(w2)[1])\n",
    "# print(\"w3:\",info_wifi(w3)[1])\n",
    "# print(\"w4:\",info_wifi(w4)[1])\n",
    "\n",
    "\n",
    "w_prev = w1\n",
    "w_next = w2\n",
    "\n",
    "nw11, nw12 = get_same_aps(w1,w2)\n",
    "\n",
    "nw22, nw23 = get_same_aps(w2,w3)\n",
    "nw33, nw34 = get_same_aps(w3,w4)\n",
    "nw41, nw44 = get_same_aps(w1,w4)\n",
    "nw51, nw53 = get_same_aps(w1,w3)\n",
    "\n",
    "print(\"nw11:\",info_wifi(nw11)[1])\n",
    "print(\"nw12:\",info_wifi(nw12)[1])\n",
    "\n",
    "# print(\"nw22:\",info_wifi(nw22)[1])\n",
    "# print(\"nw23:\",info_wifi(nw23)[1])\n",
    "\n",
    "# print(\"nw33:\",info_wifi(nw33)[1])\n",
    "# print(\"nw34:\",info_wifi(nw34)[1])\n",
    "\n",
    "# print(\"nw41:\",info_wifi(nw41)[1])\n",
    "# print(\"nw44:\",info_wifi(nw44)[1])\n",
    "\n",
    "# print(\"nw51:\",info_wifi(nw51)[1])\n",
    "# print(\"nw53:\",info_wifi(nw53)[1])\n",
    "\n",
    "wifi_linear_interpolation(nw11,nw12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MDTW():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rss_by_threshold(rss_array, threshold):\n",
    "    return [rss for rss in rss_array if rss >= threshold]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_point(point,boolean_func):\n",
    "    point['wifiData'] = [p for p in point['wifiData'] if boolean_func(p)]\n",
    "    # def update(data,func):\n",
    "    #     return {\n",
    "    #         'timestamp': data['timestamp'],\n",
    "    #         'level': data['level'],\n",
    "    #         'frequency': data['frequency'],\n",
    "    #         'capabilities': data['capabilities'],\n",
    "    #         'BSSID': data['BSSID'],\n",
    "    #         'SSID': data['SSID'],\n",
    "    #     }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 35 0\n",
      "35 0 -1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': 304199259625,\n",
       "  'level': -36,\n",
       "  'frequency': 5260,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '94:b3:4f:a3:a7:54',\n",
       "  'SSID': 'Afeka-Staff'},\n",
       " {'timestamp': 304199259631,\n",
       "  'level': -36,\n",
       "  'frequency': 5260,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '94:b3:4f:a3:a7:55',\n",
       "  'SSID': 'Afeka-Students'},\n",
       " {'timestamp': 304199259620,\n",
       "  'level': -37,\n",
       "  'frequency': 5260,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '94:b3:4f:a3:a7:50',\n",
       "  'SSID': 'Afeka-Wifi-Open'},\n",
       " {'timestamp': 304199259591,\n",
       "  'level': -64,\n",
       "  'frequency': 5240,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '94:b3:4f:a3:25:e5',\n",
       "  'SSID': 'Afeka-Students'},\n",
       " {'timestamp': 304199259586,\n",
       "  'level': -65,\n",
       "  'frequency': 5240,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '94:b3:4f:a3:25:e4',\n",
       "  'SSID': 'Afeka-Staff'},\n",
       " {'timestamp': 304199259576,\n",
       "  'level': -64,\n",
       "  'frequency': 5240,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '94:b3:4f:a3:25:e0',\n",
       "  'SSID': 'Afeka-Wifi-Open'},\n",
       " {'timestamp': 304199259490,\n",
       "  'level': -68,\n",
       "  'frequency': 5220,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '5c:df:89:89:04:f4',\n",
       "  'SSID': 'Afeka-Staff'},\n",
       " {'timestamp': 304199259494,\n",
       "  'level': -69,\n",
       "  'frequency': 5220,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '5c:df:89:89:04:f5',\n",
       "  'SSID': 'Afeka-Students'},\n",
       " {'timestamp': 304199259483,\n",
       "  'level': -69,\n",
       "  'frequency': 5220,\n",
       "  'capabilities': '[ESS]',\n",
       "  'BSSID': '5c:df:89:89:04:f0',\n",
       "  'SSID': 'Afeka-Wifi-Open'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1['wifiData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-36, -36, -37, -64, -65, -64, -68, -69, -69]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rss(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_missing_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_interpolation(rss_array, f1, f2):\n",
    "    n = get_num_interpolation(f1, f2)\n",
    "    interpolated_rss = []\n",
    "    for i in range(len(rss_array) - 1):\n",
    "        for j in range(n):\n",
    "            interpolated_rss.append(linear_interpolation(rss_array[i], rss_array[i + 1], n, j))\n",
    "    interpolated_rss.append(rss_array[-1]) \n",
    "    return interpolated_rss\n",
    "\n",
    "def normalize(array):\n",
    "    mean = np.mean(array)\n",
    "    std_dev = np.std(array)\n",
    "    return [(val - mean) / std_dev for val in array]\n",
    "\n",
    "def calculate_weights(rss_array):\n",
    "    max_rss = max(rss_array)\n",
    "    return [math.exp(rss / max_rss) for rss in rss_array]\n",
    "\n",
    "def compute_weighted_distance(rss, rssdb, weights):\n",
    "    p = len(rss)\n",
    "    distance = 0\n",
    "    for k in range(p):\n",
    "        distance += weights[k] * (rss[k] - rssdb[k]) ** 2\n",
    "    return distance\n",
    "\n",
    "def mdtw_with_wls(rss, rssdb, weights):\n",
    "    n = len(rss)\n",
    "    m = len(rssdb)\n",
    "    d = np.zeros((n, m))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            d[i][j] = compute_weighted_distance(rss[i], rssdb[j], weights)\n",
    "\n",
    "    D = np.zeros((n, m))\n",
    "    D[0][0] = d[0][0]\n",
    "\n",
    "    for i in range(1, n):\n",
    "        D[i][0] = d[i][0] + D[i - 1][0]\n",
    "\n",
    "    for j in range(1, m):\n",
    "        D[0][j] = d[0][j] + D[0][j - 1]\n",
    "\n",
    "    for i in range(1, n):\n",
    "        for j in range(1, m):\n",
    "            D[i][j] = d[i][j] + min(D[i - 1][j], D[i][j - 1], D[i - 1][j - 1])\n",
    "\n",
    "    return D[n - 1][m - 1]\n",
    "\n",
    "def weighted_least_squares(positions, distances, sigma):\n",
    "    weights = [1 / math.exp(di ** 2 / (2 * sigma ** 2)) for di in distances]\n",
    "    total_weight = sum(weights)\n",
    "\n",
    "    normalized_weights = [w / total_weight for w in weights]\n",
    "\n",
    "    estimated_x = sum(normalized_weights[i] * positions[i][0] for i in range(len(positions)))\n",
    "    estimated_y = sum(normalized_weights[i] * positions[i][1] for i in range(len(positions)))\n",
    "\n",
    "    return {'x': estimated_x, 'y': estimated_y}\n",
    "\n",
    "def match_fingerprints(user_input, database_fingerprints):\n",
    "    matched_rss = []\n",
    "    matched_dbrss = []\n",
    "\n",
    "    for user_network in user_input:\n",
    "        db_network = next((db_network for db_network in database_fingerprints if db_network['ssid'] == user_network['ssid']), None)\n",
    "        if db_network:\n",
    "            matched_rss.append(user_network['rss'])\n",
    "            matched_dbrss.append(db_network['rss'])\n",
    "\n",
    "    return {'matched_rss': matched_rss, 'matched_dbrss': matched_dbrss}\n",
    "\n",
    "def estimate_position(user_input, database_fingerprints, threshold, f1, f2, sigma, r):\n",
    "    matched = match_fingerprints(user_input, database_fingerprints)\n",
    "\n",
    "    filtered_rss = [filter_rss_by_threshold(rss_array, threshold) for rss_array in matched['matched_rss']]\n",
    "\n",
    "    interpolated_rss = [adaptive_interpolation(rss_array, f1, f2) for rss_array in filtered_rss]\n",
    "\n",
    "    normalized_rss = [normalize(rss) for rss in interpolated_rss]\n",
    "    normalized_dbrss = [normalize(rss) for rss in matched['matched_dbrss']]\n",
    "\n",
    "    weights = calculate_weights([val for sublist in interpolated_rss for val in sublist])\n",
    "\n",
    "    distances = [mdtw_with_wls(rss, normalized_dbrss[i], weights) for i, rss in enumerate(normalized_rss)]\n",
    "\n",
    "    sorted_distances = sorted(\n",
    "        [{'distance': d, 'position': (database_fingerprints[i]['x'], database_fingerprints[i]['y'])} for i, d in enumerate(distances)],\n",
    "        key=lambda x: x['distance']\n",
    "    )\n",
    "\n",
    "    top_r = sorted_distances[:r]\n",
    "\n",
    "    positions = [item['position'] for item in top_r]\n",
    "    distance_values = [item['distance'] for item in top_r]\n",
    "\n",
    "    estimated_position = weighted_least_squares(positions, distance_values, sigma)\n",
    "\n",
    "    return estimated_position\n",
    "\n",
    "# Example database fingerprints with positions\n",
    "database_fingerprints = [\n",
    "    {\n",
    "        'ssid': 'network1',\n",
    "        'rss': [-78, -82, -85, -88, -74],\n",
    "        'x': 5,\n",
    "        'y': 10\n",
    "    },\n",
    "    {\n",
    "        'ssid': 'network2',\n",
    "        'rss': [-61, -63, -60, -55, -52],\n",
    "        'x': 15,\n",
    "        'y': 20\n",
    "    }\n",
    "]\n",
    "\n",
    "# Example user input\n",
    "user_input = [\n",
    "    {\n",
    "        'ssid': 'network1',\n",
    "        'rss': [-80, -75, -90, -60, -50]\n",
    "    },\n",
    "    {\n",
    "        'ssid': 'network2',\n",
    "        'rss': [-62, -65, -67, -70, -69]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Parameters for position estimation\n",
    "threshold = -70\n",
    "f1 = 0.5  # Target sampling frequency\n",
    "f2 = 0.125  # Original sampling frequency\n",
    "sigma = 1  # Configuration parameter for exponential function\n",
    "r = 2  # Number of top positions to consider\n",
    "\n",
    "estimated_position = estimate_position(user_input, database_fingerprints, threshold, f1, f2, sigma, r)\n",
    "\n",
    "print(\"Estimated Position:\", estimated_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((np.array(point1) - np.array(point2)) ** 2))\n",
    "\n",
    "def knn(data, query, k, distance_fn=euclidean_distance):\n",
    "    \"\"\"\n",
    "    k-Nearest Neighbors algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    data: list of tuples (each tuple is a data point, with the last element being the label)\n",
    "    query: tuple (the data point to query)\n",
    "    k: int (the number of nearest neighbors to find)\n",
    "    distance_fn: function (a function to calculate the distance between points)\n",
    "    \n",
    "    Returns:\n",
    "    The most common label among the k nearest neighbors.\n",
    "    \"\"\"\n",
    "    # Calculate distances from the query point to all points in the dataset\n",
    "    distances = []\n",
    "    for index, point in enumerate(data):\n",
    "        distance = distance_fn(point[:-1], query)\n",
    "        distances.append((distance, index))\n",
    "    \n",
    "    # Sort by distance and get the k nearest neighbors\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_nearest_indices = [index for _, index in distances[:k]]\n",
    "    \n",
    "    # Get the labels of the k nearest neighbors\n",
    "    k_nearest_labels = [data[i][-1] for i in k_nearest_indices]\n",
    "    \n",
    "    # Return the most common label\n",
    "    return Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "\n",
    "# Example usage:\n",
    "data = [\n",
    "    (2.1, 3.1, 'A'),\n",
    "    (1.3, 3.3, 'A'),\n",
    "    (3.5, 2.0, 'B'),\n",
    "    (3.1, 2.2, 'B'),\n",
    "    (2.0, 1.0, 'B')\n",
    "]\n",
    "\n",
    "query = (3.0, 3.0)\n",
    "k = 3\n",
    "print(knn(data, query, k))  # Output: 'A'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
